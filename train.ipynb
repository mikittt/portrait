{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cPickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-14475dea3d93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cPickle'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from chainer import cuda, Variable, optimizers\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "from model import FaceSwapNet\n",
    "from model import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_setup(ORIGINAL_VGG,VGG):\n",
    "    VGG.conv1_1 = ORIGINAL_VGG.conv1_1\n",
    "    VGG.conv1_2 = ORIGINAL_VGG.conv1_2\n",
    "    VGG.conv2_1 = ORIGINAL_VGG.conv2_1\n",
    "    VGG.conv2_2 = ORIGINAL_VGG.conv2_2\n",
    "    VGG.conv3_1 = ORIGINAL_VGG.conv3_1\n",
    "    VGG.conv3_2 = ORIGINAL_VGG.conv3_2\n",
    "    VGG.conv3_3 = ORIGINAL_VGG.conv3_3\n",
    "    VGG.conv4_1 = ORIGINAL_VGG.conv4_1\n",
    "    VGG.conv4_2 = ORIGINAL_VGG.conv4_2\n",
    "    \"\"\"\n",
    "    VGG.conv4_3 = ORIGINAL_VGG.conv4_3\n",
    "    VGG.conv5_1 = ORIGINAL_VGG.conv5_1\n",
    "    VGG.conv5_2 = ORIGINAL_VGG.conv5_2\n",
    "    VGG.conv5_3 = ORIGINAL_VGG.conv5_3\n",
    "    VGG.fc6=ORIGINAL_VGG.fc6\n",
    "    VGG.fc7=ORIGINAL_VGG.fc7\n",
    "    \"\"\"\n",
    "    return VGG\n",
    "    \n",
    "def open_and_resize_image(content_path, style_path, target_width):\n",
    "    X=[]\n",
    "    for size in [8,16,32,64,128]:\n",
    "        X_tmp=[]\n",
    "        for path in glob.glob(content_path+\"*.jpg\"):\n",
    "            image = Image.open(path).convert('RGB')\n",
    "            X_tmp.append(np.array(image.resize((size, size), Image.BILINEAR)).transpose(2,0,1))\n",
    "        X.append(X_tmp)\n",
    "        \n",
    "    style=[]\n",
    "    for path in glob.glob(style_path+\"*\"):\n",
    "        image = Image.open(path).convert('RGB')\n",
    "        width, height = image.size\n",
    "        target_height = int(round(float(height * target_width) / width))\n",
    "        style.append(np.array(image.resize((target_width, target_height), Image.ANTIALIAS)).transpose(2,0,1))\n",
    "    \n",
    "    X=np.array(X)\n",
    "    style=np.array(style)\n",
    "    \n",
    "    return X,style\n",
    "\n",
    "\n",
    "\n",
    "def total_variation(x):\n",
    "    xp = cuda.get_array_module(x.data)\n",
    "    b, ch, h, w = x.data.shape\n",
    "    wh = Variable(xp.asarray([[[[1], [-1]], [[0], [0]], [[0], [0]]], [[[0], [0]], [[1], [-1]], [[0], [0]]], [[[0], [0]], [[0], [0]], [[1], [-1]]]], dtype=xp.float32), volatile=x.volatile)\n",
    "    ww = Variable(xp.asarray([[[[1, -1]], [[0, 0]], [[0, 0]]], [[[0, 0]], [[1, -1]], [[0, 0]]], [[[0, 0]], [[0, 0]], [[1, -1]]]], dtype=xp.float32), volatile=x.volatile)\n",
    "    return F.sum(F.convolution_2d(x, W=wh) ** 2) + F.sum(F.convolution_2d(x, W=ww) ** 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vgg=VGG19()\n",
    "with open(\"vgg19.pkl\",\"rb\") as i:\n",
    "    orig_vgg19=pickle.load(i)\n",
    "vgg=conv_setup(orig_vgg19,vgg)\n",
    "\n",
    "cnn=FaceSwapNet(content_path=\"data/content/\",style_path=\"data/style/\",target_width=128)\n",
    "\n",
    "X,style=load_data()\n",
    "X_train=[]\n",
    "X_test=[]\n",
    "perm=np.random.permutation(N)\n",
    "for i in range(len(X)):\n",
    "    X_train.append(X[i][perm[:len(X[i])//10*9]])\n",
    "    X_test.append(X[i][perm[len(X[i])//10*9:]])\n",
    "\n",
    "optimizer=optimizer.Adam(alpha=0.001)\n",
    "optimizer.setup(cnn)\n",
    "\n",
    "cnn.to_gpu()\n",
    "vgg.to_gpu()\n",
    "\n",
    "xp=cnn.xp\n",
    "\n",
    "N=len(X_train)\n",
    "batch_size=16\n",
    "kernel=3\n",
    "alpha=1.0\n",
    "beta=0\n",
    "gamma=0.3\n",
    "n_epoch=10000\n",
    "\n",
    "style=Variable(xp.array(style,dtype=xp.float32),volatile=True)\n",
    "style-=xp.array([[[[124]],[[117]],[[104]]]])\n",
    "style_feature=vgg(style)\n",
    "style_patch=[]\n",
    "\n",
    "for name in [\"3_1\",\"4_1\"]:\n",
    "    patch=xp.array([style_feature[name][0,:,i:i+kernel,j:j+kernel].data/xp.lilalg.norm(style_feature[name][0,:,i:i+kernel,j:j+kernel].data) for i in range(style_feature[name].shape[2]-kernel+1) for j in range(style_feature[name].shape[3]-kernel+1)])\n",
    "    style_patch.append(patch)\n",
    "del patch\n",
    "\n",
    "\n",
    "for epoch in range(1,n_epoch+1):\n",
    "    print(\"epoch\",epoch)\n",
    "    perm=xp.random.permutation(N)\n",
    "    L=0\n",
    "    if epoch in np.arange(1,21)*20:\n",
    "        beta+=1\n",
    "    for i in range(0,N,batch_size):\n",
    "        x1=xp.array(X_train[0]perm[i,i:i+batch_size]/127.5-1.).astype(xp.float32)\n",
    "        x2=xp.array(X_train[1]perm[i,i:i+batch_size]/127.5-1.).astype(xp.float32)\n",
    "        x3=xp.array(X_train[2]perm[i,i:i+batch_size]/127.5-1.).astype(xp.float32)\n",
    "        x4=xp.array(X_train[3]perm[i,i:i+batch_size]/127.5-1.).astype(xp.float32)\n",
    "        x5=xp.array(X_train[4]perm[i,i:i+batch_size]/127.5-1.).astype(xp.float32)\n",
    "        \n",
    "        optimizer.zero_grads()\n",
    "        \n",
    "        swap_X=cnn(x1,x2,x3,x4,x5)\n",
    "        contents=Variable(xp.array(X_train[-1][perm[i,i:i+batch_size]]),volatile=True)\n",
    "        swap_X-=xp.array([[[[124]],[[117]],[[104]]]])\n",
    "        contents-=xp.array([[[[124]],[[117]],[[104]]]])\n",
    "        \n",
    "        swap_feature=vgg(swap_X)\n",
    "        content_feature=vgg(contents)\n",
    "        \n",
    "        L_content=F.mean_squared_error(Variable(content_feature[\"4_2\"].data), swap_feature[\"4_2\"])\n",
    "        L_style=0\n",
    "        for s,name in enumerate([\"3_1\",\"4_1\"]):\n",
    "            L_style+=cnn.local_patch(swap_X[name],xp.arrray(style_patch[s],dtype=xp.float32))\n",
    "        L_style/=s\n",
    "        L_tv=total_variation(swap_X)\n",
    "        L=alpha*L_content+beta*L_style+gamma*L_tv\n",
    "        \n",
    "        L.backward()\n",
    "        optimizer.update()\n",
    "    \n",
    "    print(\"train mean loss={}\".format(L/N))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
